# RAID
- 서버 컴퓨터 저장장치는 대부분 RAID를 사용한다.
- RAID : Redundant Array of Inexpensive(Independant) Disks
- 하드웨어 RAID : 제조업체에서 하드디스크를 연결한 장비를 설치
    - 안정적이지만 / 고가
- 소프트웨어 RAID 
    - 운영체제(os)에서 지원하는 방식
    - 하드웨어 RAID 보다 덜 안정적 / 저렴한 비용으로 안전하게 데이터 저장
- RAID Level
    1. 단순 볼륨
    2. Linear RAID : 2개 이상의 하드디스크를 연결
    3. RAID 0 : Stripping
        - 여러개의 디스크를 병렬로 배치하여 사용
        - 100%의 공간효율성, 빠른속도
        - 결함 허용 안됨 : 데이터의 위험성이 증가. 하나가 고장나면 데이터 손상
        - 빠른 성능이 필요하지만, 잃어버려도 문제가 없는 데이터
    4. RAID 1 : Mirroring
        - 여러 개의 디스크에 데이터를 중복하여 기록
        - 하드 디스크의 용량을 절반만 사용할 수 있음.
        - 결함 허용 : 하나가 고장이 나더라도 데이터 손상 없음.
        - 데이터 저장에 2배의 용량이 필요, 50% 공간 효율성
        - 중요한 데이터를 저장하기에 적합
    5. RAID 2, 3, 4는 실제 사용하지 않음. : 패리티 비트 사용
    6. RAID 5
        - RAID 1의 안정성 + RAID 0의 공간효율성
        - 패리티 비트를 사용하여 데이터 복구 ( 각 멤버 디스크에 순환 저장 )
        - 한 디스크가 고장나도 패리티 비트를 통해 저장상태를 유추 + 데이터 사용 가능
        - 최소 3개 이상의 디스크가 필요
        - 공간 효율성은 (n-1)
        - 3 ~ 9 개 정도 Disk RAID는 5번 
    7. RAID 6
        - RAID 5 구성방식을 개선한 것
        - 2개의 패리티를 사용함
        - 2개의 하드디스크가 동시에 고장나더라도 데이터에 이상이 없다.
        - 공간 효율성은 (n-2)
        - 최소 4개의 하드디스크를 구성해야함
        - 공간 효율은 약간 낮지만 데이터 신뢰도는 더욱 향상
        - 속도는 약간 떨어짐(RAID 5보다)
        - Disk 10개 이상의(대량의 디스크 사용) 경우는 6번을 주로 사용

- 명령어
    - ls -l /dev/sd* : SCSI 드라이브에 설치된 장치 확인

    ```
    fdisk /dev/sd{}      - 하드디스크 선택
    command : n          - 새로운 파티션
    select : p           - primary 선택
    partition number : 1 - 파티션 1번 선택
    first sector : (enter) - 시작 섹터 번호(기본값) 
    last sector : (enter)  - 마지막 섹터 번호 (기본값)
    Command : t         - 파일 시스템 유형 선택
    hex code : fd       - linux raid auto
    command : p         - 설정 내용 확인
    command : w         - 설정저장
    ```
    - Multi Device ADMinistartor 설치
        - `apt -y install mdadm`

## mdadm으로 RAID 구축 순서
1. 선처리 작업 (파티션 만들기)
    - fdisk를 통해 파티션 만들고
    - type을 Linux raid auto로 준다.
2. 볼륨 그룹 생성
    `` `
    # 한 줄로 생성 명령
    mdadm --create /dev/md9    # md9라는 장치(논리 볼륨)에 RAID 생성
    --level=linear             # linear RAID 지정
    --raid-devices=2           # 장치 몇개 연결할지 선택
    /dev/sdb1 /dev/sdc1        # 연결하는 장치 이름 (장치 갯수만큼)
    ```
3. 파일 시스템 포맷
    `mkfs.ext4 [논리볼륨]`
    `mkfs.ext4 /dev/md9`
4. 마운트
    - 연결할 디렉토리 생성
        - `mkdir /raidLinear` [연결할디렉토리명]
        - `mount /dev/md9 /raidLinear` [장치명] [연결할디렉토리명]
5. /etc/fstab에 등록
    - [장치명] [마운트위치] [타입] [옵션] [pass] [dump]
    - /dev/md9 /raidLinear ext4 defaults 0 0
* 확인용 보조 명령
    - `ls -l /dev/md*`  : 논리볼륨 확인
    - `mdadm --detail /dev/md9` : [논리볼륨] 레이드 자세히
    - `df` : 마운트된 디스크 공간 확인
    - `mdadm --detail --scan` : RAID 확인
* 기타명령
    - `mdadm --stop /dev/md9` [논리볼륨] : 장치 중지
    - `mdadm --run /dev/md9` [논리볼륨] : 중지된 장치 가동

- mdadm 버그로 인한 설정 추가
    1. `mdadm --detail --scan`    # 명령 후 결과물 복사
    2. `nano /etc/mdadm/mdadm.conf` #  최하단에 붙여넣기
    3. `name=server:x` 부분 삭제하고 저장
    4. `update-initramfs -u`  # 변경설정 적용
    5. reboot # 재부팅
    * 확인 `df | grep dev/md`, `ls /dev/md*`

- 하드디스크 고장 확인 작업
    1. cp명령 사용하여 아무 파일 복사
        - /raid0, raid1, raid5 /raid9
    2. 예시와 같이 하드디스크 제거 후 부팅
        - `ls -l /dev/sd*`로 확인
        - `df` 명령으로 확인
        - `mdadm --detail --scan` 으로 확인
    3. 결함 허용 되는 RAID 재가동
        - `mdadm --run /dev/md1`
        - `mdadm --run /dev/md5`
    4. 마운트
        - `mount /dev/md1 /raid1`
    5. 파일 확인
        - `ls /raid1`
    6. 장치 상태 확인
        - `mdadm --detail /dev/md1`

# 원상복구
1. 물리적 하드 추가
    - fdisk로 파티션 잡기
    - 결함허용 RAID
        - `mdadm /dev/md1 --add [파티션(/dev/sdg1)]`
    - 결함허용하지 않는 RAID
        - mdadm --stop /dev/md0     #INACTIVE로 사용중인 레이드 정지
        - `mdadm --create`로 재생성
        - mdadm --create /dev/md0 --level=1 -raid-devices=2 /dev/sdd1 /dev/sde1 
    - 확인
        - mdadm --detail /dev/md1
    - 결함 허용하지 않는 RAID 복구의 경우 운이 좋으면 복구 될 수 있지만, 여기에 기대할 수 없다.
    - RAID를 통해 안전성을 확보할 수 있지만, 랜섬웨어 등 복구 불가능 경우가 있으므로 별도의 백업은 필수적
